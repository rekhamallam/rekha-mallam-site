<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rekha Mallam – Data Engineer</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <nav class="navbar">
    <div class="nav-container">
      <span class="logo">Rekha Mallam</span>
      <ul class="nav-links">
        <li><a href="#summary">Summary</a></li>
        <li><a href="#skills">Skills</a></li>
        <li><a href="#experience">Experience</a></li>
        <li><a href="#certifications">Certifications</a></li>
        <li><a href="#education">Education</a></li>
        <li><a href="#contact">Contact</a></li>
      </ul>
    </div>
  </nav>

  <header class="hero">
    <h1>Hi, I’m Rekha Mallam</h1>
    <p class="subheading">Senior Data Engineer – Cloud-Native | ETL Expert | Real-Time Data Specialist</p>
  </header>

  <main class="container">
    <section id="summary">
      <h2>Professional Summary</h2>
         <p>Results-oriented Data Engineer with 14+ years of experience designing, modernizing, and optimizing pipelines on cloud Azure, AWS using Snowflake. Proven in performance tuning, dbt, Spark, and collaboration with engineering/product teams.</p>
    </section>

    <section id="skills">
      <h2>Technical Skills</h2>
      <ul>
        <li>Cloud: Azure, AWS </li>
        <li>Data: Spark, PySpark, dbt, Iceberg, Airflow</li>
        <li>ETL: DataStage, Informatica</li>
        <li>Modeling: Star & Snowflake Schema</li>
        <li>DBs: Oracle, PostgreSQL, Snowflake</li>
        <li>Tools: GitHub, Jira </li>
        <li>Languages: Python, SQL, Shell, Scala</li>
        <li>BI: Looker, Tableau</li>
      </ul>
    </section>

    <section id="experience">
      <h2>Professional Experience</h2>
      <article>
        <h3>IBM – Data Engineer</h3>
        <p><strong>Client:</strong> State of Colorado, USA | <strong>Jun 2021 – Present</strong></p>
        <ul>
          <li>Leveraged Snowpipe to auto-ingest daily HIPAA/BHA change CSVs from S3 into Snowflake BIDM warehouse, initiating continuous ELT and cutting data-availability SLA from 2 h to 15 m.</li>
          <li>Refactored dbt models for the Snowflake BIDM warehouse—adopted incremental & ephemeral strategies, trimmed run-time 40 % and cut warehouse credit consumption by 20%.</li>
          <li>Automated S3-triggered CSV validation and load workflows with AWS Lambda, eliminating manual scripts, accelerating data availability.</li>
          <li>Built ELT pipelines with dbt & Snowflake tasks, incorporating row-count reconciliation and checksum audits to guarantee data integrity.</li>
        </ul>
      </article>
      <article>
        <h3>IBM Watson – Sr. Data Warehouse Engineer</h3>
        <p><strong>Jan 2018 – Feb 2021</strong></p>
        <ul>
          <li>Migrated two legacy marts to Azure Synapse with the T-SQL COPY command for parallel bulk loads.</li>
          <li>Built Azure Data Factory (Mapping Data Flow) pipelines with Conditional Split, Derived Column and Surrogate Key transforms to support slowly changing dimensions</li>
        </ul>
      </article>
      <article>
  <h3>Freddie&nbsp;Mac – ETL Developer</h3>
  <p><strong>Sep&nbsp;2013 – Dec&nbsp;2017&nbsp;|&nbsp;McLean, VA</strong></p>
  <ul>
    <li>Authored 200+ IBM DataStage jobs ingesting flat files, Oracle, and DB2 sources into an EDW supporting credit-risk analytics.</li>
    <li>Parameterised common logic with job sequencers and shared routines, reducing maintenance effort by 25 %.</li>
    <li>Automated regression tests in QuerySurge (row-count&nbsp;&amp;&nbsp;hash totals) to certify monthly releases with &lt; 2 % defect leakage.</li>
  </ul>
</article>

<article>
  <h3>Avery&nbsp;Dennison – ETL Consultant <span>(Contract via&nbsp;TCS)</span></h3>
  <p><strong>Jan&nbsp;2007 – Mar&nbsp;2013&nbsp;|&nbsp;USA</strong></p>
  <ul>
    <li>Built a Kimball-style data warehouse in Informatica PowerCenter, delivering 300 + mappings with Update Strategy logic to perform Type 2 SCD loads for dimension tables.&nbsp;&amp;&nbsp;</li>
    <li>Scripted UNIX shell wrappers for end-to-end job orchestration, cutting hand-offs between Ops and Dev by 30 %.</li>
    <li>Produced conceptual &amp; physical models in Erwin, partnering with BI to align star schemas to reporting needs.</li>
  </ul>
</article>
    </section>
 <section id="certifications">
      <h2>Certifications</h2>
      <ul>
        <li>Azure Data Engineer Associate – Expected Jul 2025</li>
        <li>SnowPro Core Certified – Expected Aug 2025</li>
        <li>DataExpert.io Bootcamp – Cloud Data Engineering</li>
      </ul>
    </section>

    <section id="education">
      <h2>Education</h2>
      <p>M.S. Computer Science, JNTU, India (Graduated 2007)</p>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <p>Email: <a href="mailto:rekha.mallam@gmail.com">rekha.mallam@gmail.com</a></p>
      <p>LinkedIn: <a href="https://linkedin.com/in/rekha-mallam-024427204" target="_blank" rel="noopener noreferrer">/rekha-mallam</a></p>
    </section>
  </main>

  <footer>
    <p>© 2025 Rekha Mallam. Built with clarity and purpose.</p>
  </footer>
</body>
</html>
